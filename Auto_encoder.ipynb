{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UuETARWdZnw9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "metadata": {
        "id": "lxGPBtEUZruK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train data:\",x_train.shape)\n",
        "print(\"test data:\",x_test.shape)\n",
        "\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])"
      ],
      "metadata": {
        "id": "xtbe3nqBZzes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train after reshape:\",x_train.shape)\n",
        "print(\"test after reshape:\",x_test.shape)"
      ],
      "metadata": {
        "id": "esbr7XU4Z4X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "rFQjdFBQZ6K_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# network parameters\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 32\n",
        "kernel_size = 3\n",
        "latent_dim = 16\n",
        "# encoder/decoder number of CNN layers and filters per layer\n",
        "layer_filters = [32, 64]"
      ],
      "metadata": {
        "id": "EPzLflskZ8Lg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the autoencoder model\n",
        "# first build the encoder model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "# stack of Conv2D(32)-Conv2D(64)\n",
        "for filters in layer_filters:\n",
        "    x = Conv2D(filters=filters,\n",
        "    kernel_size=kernel_size,\n",
        "    activation='relu',\n",
        "    strides=2,\n",
        "    padding='same')(x)"
      ],
      "metadata": {
        "id": "Jb4VcGpFZ-We"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape = K.int_shape(x)\n",
        "shape"
      ],
      "metadata": {
        "id": "zz913S-YaGbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate latent vector\n",
        "x = Flatten()(x)\n",
        "latent = Dense(latent_dim, name='latent_vector')(x)\n",
        "# instantiate encoder model\n",
        "encoder = Model(inputs,\n",
        "latent,\n",
        "name='encoder')\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "KO6bhfwsaQQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the decoder model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
        "# use the shape (7, 7, 64) that was earlier saved\n",
        "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
        "# from vector to suitable shape for transposed conv\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)"
      ],
      "metadata": {
        "id": "Gdx7wiS-aZVw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filters in layer_filters[::-1]:\n",
        "            x = Conv2DTranspose(filters=filters, kernel_size=kernel_size,activation='relu',strides=2,  padding='same')(x)"
      ],
      "metadata": {
        "id": "PkFGNtqRafsy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = Conv2DTranspose(filters=1,\n",
        "                                    kernel_size=kernel_size,\n",
        "                                    activation='sigmoid',\n",
        "                                    padding='same',\n",
        "                                    name='decoder_output')(x)"
      ],
      "metadata": {
        "id": "UuVk4CGyakU6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "lP01v8tuammp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(inputs,\n",
        "                            decoder(encoder(inputs)),\n",
        "                            name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "fjrBmu1-apqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(loss='mse', optimizer='adam')"
      ],
      "metadata": {
        "id": "lB4LuVbpasgB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train,\n",
        "                        x_train,\n",
        "                        validation_data=(x_test, x_test),\n",
        "                        epochs=3,\n",
        "                        batch_size=batch_size)"
      ],
      "metadata": {
        "id": "6xm97qh-au4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_decoded = autoencoder.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3mQATucaxP0",
        "outputId": "8ec74489-8d08-43e1-ce9e-cd56f327b0dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = np.concatenate([x_test[:8], x_decoded[:8]])\n",
        "imgs = imgs.reshape((4, 4, image_size, image_size))\n",
        "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
        "plt.figure()\n",
        "plt.axis('off')\n",
        "plt.title('Input: 1st 2 rows, Decoded: last 2 rows')\n",
        "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
        "plt.savefig('input_and_decoded.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GRxYFquia2E_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}