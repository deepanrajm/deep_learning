{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695fae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neo4j\n",
      "  Downloading neo4j-5.28.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\deepa\\.conda\\envs\\rag\\lib\\site-packages (from neo4j) (2025.1)\n",
      "Downloading neo4j-5.28.2-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: neo4j\n",
      "Successfully installed neo4j-5.28.2\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d0cbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepa\\.conda\\envs\\rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing graph data...\n",
      "Building new graph in Neo4j...\n",
      "Graph build complete.\n",
      "Fetching node data from Neo4j for embedding...\n",
      "Loading embedding model and creating FAISS index...\n",
      "FAISS index created.\n",
      "Setting up local LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepa\\.conda\\envs\\rag\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\deepa\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Querying the Neo4j-Powered Knowledge Tree RAG ---\n",
      "\n",
      "> Question: What were the total sales in the North region?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "< Answer: Total sales totaled $19,959.00 from 5,800 units sold.\n",
      "\n",
      "Find a Home\n",
      "\n",
      "How About a Boat? Can You Find a Home?\n",
      "\n",
      "What Are the Differences in the Sales Levels by Province?\n",
      "\n",
      "Can You Find Your Home in North Ontario? If so, what can we expect to see in sales and purchases?\n",
      "\n",
      "More Information about The North End of Ontario, the West End of Ontario and Ontario of Ontario.\n",
      "\n",
      "Awards\n",
      "\n",
      "Famous for their Outlaws, Famous for its Beautiful and Glorious Coast, and Famous for their Famous Ship. More about The North End of Ontario, The West End of Ontario and Ontario of Ontario.\n",
      "\n",
      "The Coast and the Ship have been a very good indicator of trade flow for several hundred years. As a North West Coast Ship and an East Coast Ship, the shipping will be very good as it's very small. For example, in a city known for its high quality and strong maritime resources, one might expect this to become a trend by the time the North West Coast Ship ships arrive. A few thousand vessels come to Toronto each year as the North West Coast Ship ships make their way inland to get their freight. At Toronto's busiest port, the North West Coast\n",
      "\n",
      "  -- Retrieved Context Sources from Neo4j --\n",
      "  - Overall Summary: Total sales amounted to $40,125.00 from a total of 235 units sold.\n",
      "  - Region Summary for North: Total sales were $17,000.00 from 60 units sold.\n",
      "  - Region Summary for East: Total sales were $4,500.00 from 45 units sold.\n",
      "------------------------------\n",
      "\n",
      "> Question: Compare the sales performance of Laptops in the North vs. the South region.\n",
      "\n",
      "< Answer: Question: What's the difference between the North & the South's product specifications.\n",
      "\n",
      "Sales\n",
      "\n",
      "Sales\n",
      "\n",
      "Sales\n",
      "\n",
      "Sales\n",
      "\n",
      "Product Quality\n",
      "\n",
      "Quality\n",
      "\n",
      "Product Image\n",
      "\n",
      "Product Quality\n",
      "\n",
      "Product Profile\n",
      "\n",
      "Sales\n",
      "\n",
      "Sales\n",
      "\n",
      "Product Size\n",
      "\n",
      "Product Image\n",
      "\n",
      "Product Quality\n",
      "\n",
      "Product Profile\n",
      "\n",
      "Sales\n",
      "\n",
      "Sales\n",
      "\n",
      "Product Efficiency\n",
      "\n",
      "Quality\n",
      "\n",
      "Product Efficiency\n",
      "\n",
      "Quality\n",
      "\n",
      "Product Efficiency\n",
      "\n",
      "Quality\n",
      "\n",
      "Product Efficiency\n",
      "\n",
      "Product Quality\n",
      "\n",
      "Sales\n",
      "\n",
      "Product Efficiency\n",
      "\n",
      "Product Quality\n",
      "\n",
      "Quality\n",
      "\n",
      "Product Efficiency\n",
      "\n",
      "Quality\n",
      "\n",
      "Source:\n",
      "\n",
      "\n",
      "Related Thread:\n",
      "\n",
      "  -- Retrieved Context Sources from Neo4j --\n",
      "  - Product Summary for Laptop in South: Sales were $6,000.00 from 5 units sold.\n",
      "  - Region Summary for North: Total sales were $17,000.00 from 60 units sold.\n",
      "  - Product Summary for Laptop in North: Sales were $12,000.00 from 10 units sold.\n",
      "  - Region Summary for South: Total sales were $7,875.00 from 80 units sold.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "# --- Libraries for Manual RAG Implementation ---\n",
    "# pip install pandas sentence-transformers faiss-cpu torch transformers neo4j\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from transformers import pipeline\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# --- Neo4j Connection Details ---\n",
    "# IMPORTANT: Update these with your Neo4j instance details\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"classic123\" \n",
    "\n",
    "class Neo4jGraph:\n",
    "    \"\"\"A wrapper for interacting with the Neo4j database.\"\"\"\n",
    "    def __init__(self, uri, user, password):\n",
    "        self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self._driver.close()\n",
    "\n",
    "    def run_query(self, query, **params):\n",
    "        with self._driver.session() as session:\n",
    "            result = session.run(query, **params)\n",
    "            return [record for record in result]\n",
    "\n",
    "def build_graph_in_neo4j(graph, df):\n",
    "    \"\"\"Clears the existing graph and rebuilds it from the DataFrame.\"\"\"\n",
    "    # Clear existing data\n",
    "    print(\"Clearing existing graph data...\")\n",
    "    graph.run_query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "    print(\"Building new graph in Neo4j...\")\n",
    "    \n",
    "    # --- Create Root Node: Overall Summary ---\n",
    "    total_sales = df['Sale Amount'].sum()\n",
    "    total_units = df['Units Sold'].sum()\n",
    "    summary_text = (\n",
    "        f\"Overall Summary: Total sales amounted to ${total_sales:,.2f} from a total of {total_units} units sold.\"\n",
    "    )\n",
    "    graph.run_query(\n",
    "        \"CREATE (:GlobalSummary {text: $text, total_sales: $sales, total_units: $units})\",\n",
    "        text=summary_text, sales=total_sales, units=total_units\n",
    "    )\n",
    "\n",
    "    # --- Create Region Nodes and Relationships ---\n",
    "    region_summary_df = df.groupby('Region').agg({'Sale Amount': 'sum', 'Units Sold': 'sum'}).reset_index()\n",
    "    for _, row in region_summary_df.iterrows():\n",
    "        region_text = f\"Region Summary for {row['Region']}: Total sales were ${row['Sale Amount']:,.2f} from {row['Units Sold']} units sold.\"\n",
    "        graph.run_query(\n",
    "            \"\"\"\n",
    "            MATCH (g:GlobalSummary)\n",
    "            CREATE (r:Region {name: $name, text: $text, total_sales: $sales, total_units: $units})\n",
    "            CREATE (g)-[:CONTAINS_REGION]->(r)\n",
    "            \"\"\",\n",
    "            name=row['Region'], text=region_text, sales=row['Sale Amount'], units=row['Units Sold']\n",
    "        )\n",
    "\n",
    "    # --- Create Product-in-Region Nodes and Relationships ---\n",
    "    prod_region_df = df.groupby(['Region', 'Product']).agg({'Sale Amount': 'sum', 'Units Sold': 'sum'}).reset_index()\n",
    "    for _, row in prod_region_df.iterrows():\n",
    "        product_text = f\"Product Summary for {row['Product']} in {row['Region']}: Sales were ${row['Sale Amount']:,.2f} from {row['Units Sold']} units sold.\"\n",
    "        graph.run_query(\n",
    "            \"\"\"\n",
    "            MATCH (r:Region {name: $region_name})\n",
    "            CREATE (p:ProductSummary {\n",
    "                product_name: $product, \n",
    "                region: $region_name, \n",
    "                text: $text, \n",
    "                total_sales: $sales, \n",
    "                total_units: $units\n",
    "            })\n",
    "            CREATE (r)-[:SOLD_PRODUCT]->(p)\n",
    "            \"\"\",\n",
    "            region_name=row['Region'], product=row['Product'], text=product_text, sales=row['Sale Amount'], units=row['Units Sold']\n",
    "        )\n",
    "    print(\"Graph build complete.\")\n",
    "\n",
    "def create_rag_with_neo4j(graph):\n",
    "    \"\"\"\n",
    "    Creates the RAG pipeline using Neo4j as the knowledge store.\n",
    "    \"\"\"\n",
    "    # 1. Fetch all text nodes from Neo4j to embed them\n",
    "    print(\"Fetching node data from Neo4j for embedding...\")\n",
    "    results = graph.run_query(\"MATCH (n) RETURN elementId(n) AS id, n.text AS text\")\n",
    "    node_ids = [record['id'] for record in results]\n",
    "    all_docs_text = [record['text'] for record in results]\n",
    "\n",
    "    # 2. Embed and Index using SentenceTransformer and FAISS\n",
    "    print(\"Loading embedding model and creating FAISS index...\")\n",
    "    embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    doc_embeddings = embedding_model.encode(all_docs_text, convert_to_tensor=False)\n",
    "    index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
    "    index.add(np.array(doc_embeddings, dtype=np.float32))\n",
    "    print(\"FAISS index created.\")\n",
    "\n",
    "    # 3. LLM Setup\n",
    "    print(\"Setting up local LLM...\")\n",
    "    generator = pipeline(\"text-generation\", model=\"gpt2\", max_new_tokens=256)\n",
    "    \n",
    "    # 4. RAG Query Function\n",
    "    def answer_question(question, top_k=2):\n",
    "        query_embedding = embedding_model.encode([question])\n",
    "        _, indices = index.search(np.array(query_embedding, dtype=np.float32), top_k)\n",
    "        \n",
    "        # Get the IDs of the best-matching nodes from the vector search\n",
    "        matched_node_ids = [node_ids[i] for i in indices[0]]\n",
    "        \n",
    "        # **Hierarchical Context Retrieval using Cypher**\n",
    "        # For each matched node, get the node itself and its parent.\n",
    "        context_query = \"\"\"\n",
    "        UNWIND $node_ids AS nodeId\n",
    "        MATCH (n) WHERE elementId(n) = nodeId\n",
    "        OPTIONAL MATCH (p)-[]->(n) // Find parent\n",
    "        RETURN n.text AS text, p.text AS parent_text\n",
    "        \"\"\"\n",
    "        context_results = graph.run_query(context_query, node_ids=matched_node_ids)\n",
    "        \n",
    "        # Assemble context, avoiding duplicates\n",
    "        context_texts = set()\n",
    "        for record in context_results:\n",
    "            context_texts.add(record['text'])\n",
    "            if record['parent_text']:\n",
    "                context_texts.add(record['parent_text'])\n",
    "\n",
    "        context = \"\\n\\n\".join(context_texts)\n",
    "        prompt_template = f\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nHelpful Answer:\"\n",
    "        \n",
    "        generated_text = generator(prompt_template)[0]['generated_text']\n",
    "        answer = generated_text.split(\"Helpful Answer:\")[1].strip()\n",
    "        \n",
    "        return answer, list(context_texts)\n",
    "\n",
    "    return answer_question\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    csv_data = \"\"\"Date,Region,Product,Units Sold,Sale Amount\n",
    "1/5/2023,North,Laptop,10,12000\n",
    "1/6/2023,North,Keyboard,50,5000\n",
    "1/7/2023,South,Mouse,75,1875\n",
    "2/10/2023,South,Laptop,5,6000\n",
    "2/11/2023,West,Monitor,20,10000\n",
    "3/15/2023,West,Mouse,30,750\n",
    "3/16/2023,East,Keyboard,45,4500\n",
    "\"\"\"\n",
    "    df = pd.read_csv(io.StringIO(csv_data))\n",
    "    \n",
    "    # Connect to Neo4j and build the graph\n",
    "    graph = Neo4jGraph(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    build_graph_in_neo4j(graph, df)\n",
    "    \n",
    "    # Create the RAG query function\n",
    "    rag_query_function = create_rag_with_neo4j(graph)\n",
    "\n",
    "    # Query the RAG\n",
    "    print(\"\\n--- Querying the Neo4j-Powered Knowledge Tree RAG ---\")\n",
    "    questions = [\n",
    "        \"What were the total sales in the North region?\",\n",
    "        \"Compare the sales performance of Laptops in the North vs. the South region.\",\n",
    "    ]\n",
    "    for q in questions:\n",
    "        print(f\"\\n> Question: {q}\")\n",
    "        answer, sources = rag_query_function(q)\n",
    "        print(f\"\\n< Answer: {answer}\")\n",
    "        print(\"\\n  -- Retrieved Context Sources from Neo4j --\")\n",
    "        for text in sources:\n",
    "            print(f\"  - {text}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    # Clean up the connection\n",
    "    graph.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3071a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# --- Libraries for Manual RAG Implementation ---\n",
    "# pip install pandas sentence-transformers faiss-cpu torch neo4j requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# --- Neo4j Connection Details ---\n",
    "# IMPORTANT: Update these with your Neo4j instance details\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"classic123\" \n",
    "\n",
    "# --- LM Studio Connection Details ---\n",
    "# Make sure LM Studio is running and a model is loaded.\n",
    "LM_STUDIO_URL = \"http://localhost:1234/v1/chat/completions\"\n",
    "\n",
    "class Neo4jGraph:\n",
    "    \"\"\"A wrapper for interacting with the Neo4j database.\"\"\"\n",
    "    def __init__(self, uri, user, password):\n",
    "        self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self._driver.close()\n",
    "\n",
    "    def run_query(self, query, **params):\n",
    "        with self._driver.session() as session:\n",
    "            result = session.run(query, **params)\n",
    "            return [record for record in result]\n",
    "\n",
    "def build_graph_in_neo4j(graph, df):\n",
    "    \"\"\"Clears the existing graph and rebuilds it from the DataFrame.\"\"\"\n",
    "    # Clear existing data\n",
    "    print(\"Clearing existing graph data...\")\n",
    "    graph.run_query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "    print(\"Building new graph in Neo4j...\")\n",
    "    \n",
    "    # --- Create Root Node: Overall Summary ---\n",
    "    total_sales = df['Sale Amount'].sum()\n",
    "    total_units = df['Units Sold'].sum()\n",
    "    summary_text = (\n",
    "        f\"Overall Summary: Total sales amounted to ${total_sales:,.2f} from a total of {total_units} units sold.\"\n",
    "    )\n",
    "    graph.run_query(\n",
    "        \"CREATE (:GlobalSummary {text: $text, total_sales: $sales, total_units: $units})\",\n",
    "        text=summary_text, sales=total_sales, units=total_units\n",
    "    )\n",
    "\n",
    "    # --- Create Region Nodes and Relationships ---\n",
    "    region_summary_df = df.groupby('Region').agg({'Sale Amount': 'sum', 'Units Sold': 'sum'}).reset_index()\n",
    "    for _, row in region_summary_df.iterrows():\n",
    "        region_text = f\"Region Summary for {row['Region']}: Total sales were ${row['Sale Amount']:,.2f} from {row['Units Sold']} units sold.\"\n",
    "        graph.run_query(\n",
    "            \"\"\"\n",
    "            MATCH (g:GlobalSummary)\n",
    "            CREATE (r:Region {name: $name, text: $text, total_sales: $sales, total_units: $units})\n",
    "            CREATE (g)-[:CONTAINS_REGION]->(r)\n",
    "            \"\"\",\n",
    "            name=row['Region'], text=region_text, sales=row['Sale Amount'], units=row['Units Sold']\n",
    "        )\n",
    "\n",
    "    # --- Create Product-in-Region Nodes and Relationships ---\n",
    "    prod_region_df = df.groupby(['Region', 'Product']).agg({'Sale Amount': 'sum', 'Units Sold': 'sum'}).reset_index()\n",
    "    for _, row in prod_region_df.iterrows():\n",
    "        product_text = f\"Product Summary for {row['Product']} in {row['Region']}: Sales were ${row['Sale Amount']:,.2f} from {row['Units Sold']} units sold.\"\n",
    "        graph.run_query(\n",
    "            \"\"\"\n",
    "            MATCH (r:Region {name: $region_name})\n",
    "            CREATE (p:ProductSummary {\n",
    "                product_name: $product, \n",
    "                region: $region_name, \n",
    "                text: $text, \n",
    "                total_sales: $sales, \n",
    "                total_units: $units\n",
    "            })\n",
    "            CREATE (r)-[:SOLD_PRODUCT]->(p)\n",
    "            \"\"\",\n",
    "            region_name=row['Region'], product=row['Product'], text=product_text, sales=row['Sale Amount'], units=row['Units Sold']\n",
    "        )\n",
    "    print(\"Graph build complete.\")\n",
    "\n",
    "def create_rag_with_neo4j(graph):\n",
    "    \"\"\"\n",
    "    Creates the RAG pipeline using Neo4j as the knowledge store.\n",
    "    \"\"\"\n",
    "    # 1. Fetch all text nodes from Neo4j to embed them\n",
    "    print(\"Fetching node data from Neo4j for embedding...\")\n",
    "    results = graph.run_query(\"MATCH (n) RETURN elementId(n) AS id, n.text AS text\")\n",
    "    node_ids = [record['id'] for record in results]\n",
    "    all_docs_text = [record['text'] for record in results]\n",
    "\n",
    "    # 2. Embed and Index using SentenceTransformer and FAISS\n",
    "    print(\"Loading embedding model and creating FAISS index...\")\n",
    "    embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    doc_embeddings = embedding_model.encode(all_docs_text, convert_to_tensor=False)\n",
    "    index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
    "    index.add(np.array(doc_embeddings, dtype=np.float32))\n",
    "    print(\"FAISS index created.\")\n",
    "\n",
    "    # 3. RAG Query Function (LLM part is inside)\n",
    "    def answer_question(question, top_k=2):\n",
    "        query_embedding = embedding_model.encode([question])\n",
    "        _, indices = index.search(np.array(query_embedding, dtype=np.float32), top_k)\n",
    "        \n",
    "        # Get the IDs of the best-matching nodes from the vector search\n",
    "        matched_node_ids = [node_ids[i] for i in indices[0]]\n",
    "        \n",
    "        # **Hierarchical Context Retrieval using Cypher**\n",
    "        context_query = \"\"\"\n",
    "        UNWIND $node_ids AS nodeId\n",
    "        MATCH (n) WHERE elementId(n) = nodeId\n",
    "        OPTIONAL MATCH (p)-[]->(n) // Find parent\n",
    "        RETURN n.text AS text, p.text AS parent_text\n",
    "        \"\"\"\n",
    "        context_results = graph.run_query(context_query, node_ids=matched_node_ids)\n",
    "        \n",
    "        context_texts = set()\n",
    "        for record in context_results:\n",
    "            context_texts.add(record['text'])\n",
    "            if record['parent_text']:\n",
    "                context_texts.add(record['parent_text'])\n",
    "\n",
    "        context = \"\\n\\n\".join(context_texts)\n",
    "        \n",
    "        # --- LLM Generation using LM Studio ---\n",
    "        system_prompt = \"You are a helpful assistant that answers questions based ONLY on the provided context. If the answer is not in the context, say that you don't know.\"\n",
    "        user_prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nHelpful Answer:\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"local-model\", # This is a placeholder in LM Studio\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 256,\n",
    "            \"stream\": False\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(LM_STUDIO_URL, json=payload, headers={\"Content-Type\": \"application/json\"})\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            answer = result['choices'][0]['message']['content'].strip()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            answer = f\"Error communicating with LM Studio: {e}\"\n",
    "\n",
    "        return answer, list(context_texts)\n",
    "\n",
    "    return answer_question\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    csv_data = \"\"\"Date,Region,Product,Units Sold,Sale Amount\n",
    "1/5/2023,North,Laptop,10,12000\n",
    "1/6/2023,North,Keyboard,50,5000\n",
    "1/7/2023,South,Mouse,75,1875\n",
    "2/10/2023,South,Laptop,5,6000\n",
    "2/11/2023,West,Monitor,20,10000\n",
    "3/15/2023,West,Mouse,30,750\n",
    "3/16/2023,East,Keyboard,45,4500\n",
    "\"\"\"\n",
    "    df = pd.read_csv(io.StringIO(csv_data))\n",
    "    \n",
    "    # Connect to Neo4j and build the graph\n",
    "    graph = Neo4jGraph(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    build_graph_in_neo4j(graph, df)\n",
    "    \n",
    "    # Create the RAG query function\n",
    "    rag_query_function = create_rag_with_neo4j(graph)\n",
    "\n",
    "    # Query the RAG\n",
    "    print(\"\\n--- Querying the Neo4j-Powered Knowledge Tree RAG ---\")\n",
    "    questions = [\n",
    "        \"What were the total sales in the North region?\",\n",
    "        \"Compare the sales performance of Laptops in the North vs. the South region.\",\n",
    "    ]\n",
    "    for q in questions:\n",
    "        print(f\"\\n> Question: {q}\")\n",
    "        answer, sources = rag_query_function(q)\n",
    "        print(f\"\\n< Answer: {answer}\")\n",
    "        print(\"\\n  -- Retrieved Context Sources from Neo4j --\")\n",
    "        for text in sources:\n",
    "            print(f\"  - {text}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    # Clean up the connection\n",
    "    graph.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
