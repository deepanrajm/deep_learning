{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets rouge-score bert_score nltk"
      ],
      "metadata": {
        "id": "Y-jR5dBRmoz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"facebook/bart-base\" #facebook/bart-base  t5-base  google/pegasus-xsum\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "# Custom Input Example (Summarization task)\n",
        "input_text = \"summarize: The Eiffel Tower is located in Paris and was completed in 1889. It is a major tourist attraction.\"\n",
        "\n",
        "# Tokenize & Generate\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).input_ids.to(\"cuda\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(inputs, max_length=50)\n",
        "\n",
        "# Decode and Print Result\n",
        "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Input:\", input_text)\n",
        "print(\"Output:\", summary)"
      ],
      "metadata": {
        "id": "MNdIyY8I9TvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7RK9gDgQz6n"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import math\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from rouge_score import rouge_scorer\n",
        "import bert_score\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# Local Summarization Dataset\n",
        "dataset = [\n",
        "    {\n",
        "        \"article\": \"The Eiffel Tower is located in Paris and was completed in 1889. It is a major tourist attraction.\",\n",
        "        \"highlights\": \"The Eiffel Tower in Paris was completed in 1889.\"\n",
        "    },\n",
        "    {\n",
        "        \"article\": \"Python is a programming language known for its simplicity and readability. It is used widely in AI.\",\n",
        "        \"highlights\": \"Python is a simple, readable language popular in AI.\"\n",
        "    },\n",
        "    {\n",
        "        \"article\": \"The Amazon rainforest is the largest tropical rainforest in the world and is home to diverse wildlife.\",\n",
        "        \"highlights\": \"Amazon rainforest is the world's largest and rich in biodiversity.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Load Model\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "# Generate Summaries & Collect Results\n",
        "predictions = []\n",
        "references = []\n",
        "losses = []\n",
        "\n",
        "for sample in dataset:\n",
        "    input_text = \"summarize: \" + sample[\"article\"]\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True).input_ids.to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(input_ids, max_length=100)\n",
        "        pred = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        target_ids = tokenizer(sample[\"highlights\"], return_tensors=\"pt\", truncation=True).input_ids.to(\"cuda\")\n",
        "        loss = model(input_ids=input_ids, labels=target_ids).loss.item()\n",
        "\n",
        "    predictions.append(pred)\n",
        "    references.append(sample[\"highlights\"])\n",
        "    losses.append(loss)\n",
        "\n",
        "# BLEU Score\n",
        "\n",
        "def real_bleu(pred, ref):\n",
        "    pred_tokens = pred.lower().split()\n",
        "    ref_tokens = [ref.lower().split()]  # note: must be a list of references\n",
        "    smoothie = SmoothingFunction().method4  # avoids BLEU=0 for short outputs\n",
        "    return sentence_bleu(ref_tokens, pred_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
        "\n",
        "bleu_scores = [real_bleu(pred, ref) for pred, ref in zip(predictions, references)]\n",
        "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "print(f\"BLEU Score: {avg_bleu:.4f}\")\n",
        "\n",
        "# ROUGE-1, ROUGE-2, ROUGE-L\n",
        "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "rouge1, rouge2, rougeL, precision, recall = [], [], [], [], []\n",
        "\n",
        "for pred, ref in zip(predictions, references):\n",
        "    scores = scorer.score(ref, pred)\n",
        "    rouge1.append(scores[\"rouge1\"].fmeasure)\n",
        "    rouge2.append(scores[\"rouge2\"].fmeasure)\n",
        "    rougeL.append(scores[\"rougeL\"].fmeasure)\n",
        "\n",
        "\n",
        "print(f\"ROUGE-1 F1 Score: {sum(rouge1)/len(rouge1):.4f}\")\n",
        "print(f\"ROUGE-2 F1 Score: {sum(rouge2)/len(rouge2):.4f}\")\n",
        "print(f\"ROUGE-L F1 Score: {sum(rougeL)/len(rougeL):.4f}\")\n",
        "\n",
        "\n",
        "# Perplexity\n",
        "avg_loss = sum(losses) / len(losses)\n",
        "perplexity = math.exp(avg_loss)\n",
        "print(f\"Perplexity: {perplexity:.2f}\")\n",
        "\n",
        "# BERTScore\n",
        "P, R, F1 = bert_score.score(predictions, references, lang=\"en\", verbose=False)\n",
        "print(f\"BERTScore - Precision: {P.mean().item():.4f}\")\n",
        "print(f\"BERTScore - Recall: {R.mean().item():.4f}\")\n",
        "print(f\"BERTScore - F1: {F1.mean().item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WGW5tU7gEEst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}