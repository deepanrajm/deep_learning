{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Tuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdgVq87QVPd1H/5bWeltlo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepanrajm/deep_learning/blob/master/Keras_Tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb5cHdlnCx0N"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYTdIaJMDQ_b"
      },
      "source": [
        "df = tf.keras.datasets.fashion_mnist\n",
        "# spliting the data into train and testing part\n",
        "(train_df,train_labl),(test_df,test_labl) = df.load_data()\n",
        "\n",
        "#scaling the train data\n",
        "train_df=train_df/255.0\n",
        "#scaling test data\n",
        "test_df = test_df/255.0\n",
        "\n",
        "#rehaping the images into equal dim.\n",
        "train_df = train_df.reshape(len(train_df),28,28,1)\n",
        "test_df = test_df.reshape(len(test_df),28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFjNGQ9lDVCH"
      },
      "source": [
        "def build_model(hp):\n",
        "    # create model object\n",
        "    model = keras.Sequential([\n",
        "    #adding first convolutional layer    \n",
        "    keras.layers.Conv2D(\n",
        "        #adding filter \n",
        "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
        "        # adding filter size or kernel size\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
        "        #activation function\n",
        "        activation='relu',\n",
        "        input_shape=(28,28,1)),\n",
        "    # adding second convolutional layer \n",
        "    keras.layers.Conv2D(\n",
        "        #adding filter \n",
        "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
        "        #adding filter size or kernel size\n",
        "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
        "        #activation function\n",
        "        activation='relu'\n",
        "    ),\n",
        "    # adding flatten layer    \n",
        "    keras.layers.Flatten(),\n",
        "    # adding dense layer    \n",
        "    keras.layers.Dense(\n",
        "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    # output layer    \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    #compilation of model\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "#importing keras tuner\n",
        "from kerastuner import RandomSearch\n",
        "from kerastuner import Hyperband\n",
        "from kerastuner import BayesianOptimization\n",
        "#creating randomsearch object\n",
        "tuner = RandomSearch(build_model,\n",
        "                    objective='val_accuracy',\n",
        "                    max_trials = 2)\n",
        "\n",
        "#creating hyperband object\n",
        "# tuner = Hyperband(\n",
        "#     build_model,\n",
        "#     objective='val_accuracy',\n",
        "#     max_epochs=3,\n",
        "#     factor=3,\n",
        "#     hyperband_iterations=1\n",
        "# )\n",
        "\n",
        "#creating bayesian object\n",
        "# tuner = BayesianOptimization(\n",
        "#     build_model,\n",
        "#     objective='val_accuracy',\n",
        "#     max_trials=3,\n",
        "#     num_initial_points=2\n",
        "# )\n",
        "\n",
        "\n",
        "# search best parameter\n",
        "tuner.search(train_df,train_labl,epochs=3,validation_data=(train_df,train_labl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QuZhMTJDZWB"
      },
      "source": [
        "model=tuner.get_best_models(num_models=1)[0]\n",
        "#summary of best model\n",
        "print (model.summary())\n",
        "\n",
        "model.fit(test_df,test_labl,\n",
        "          epochs=10,\n",
        "          validation_split=0.1,initial_epoch=3)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}