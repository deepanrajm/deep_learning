{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e493821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.chains import LLMMathChain\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "376ccf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment and LLM Setup ---\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"42a63592c032fc7a97f972c068c18c2055f7409b1886d53270e4e77d089fd71f\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=\"not-needed\",\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    model=\"local-model\",\n",
    "    temperature=0,\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# --- Tool Definitions ---\n",
    "search_tool = SerpAPIWrapper()\n",
    "math_tool = LLMMathChain.from_llm(llm=llm, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccce833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- State Definition ---\n",
    "# Updated state to include specific reasoning for each agent.\n",
    "class AgentState(TypedDict):\n",
    "    topic: str\n",
    "    explanation: str\n",
    "    summary: str\n",
    "    calculator_result: str\n",
    "    travel_result: str\n",
    "    planner_reasoning: str\n",
    "    researcher_reasoning: str\n",
    "    travel_reasoning: str\n",
    "    route: Literal[\"research\", \"calculate\", \"travel\"] # The planner's decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3ff5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_agent(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    This agent reasons about the user's topic and then decides on the best route.\n",
    "    \"\"\"\n",
    "    print(\"---PLANNER---\")\n",
    "    topic = state[\"topic\"]\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are a planner agent. Your job is to determine the best path to take based on the user's query.\n",
    "        \n",
    "        Query: {topic}\n",
    "        \n",
    "        First, explain your reasoning for the choice you are about to make.\n",
    "        Then, on a new line, respond with ONE of the following routing decisions: 'calculate', 'travel', or 'research'.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"topic\": topic})\n",
    "    \n",
    "    # The response will contain reasoning and the decision.\n",
    "    response_text = result.content.strip()\n",
    "    \n",
    "    # Extract the decision from the last line\n",
    "    lines = response_text.split('\\n')\n",
    "    decision = lines[-1].lower()\n",
    "    reasoning = \"\\n\".join(lines[:-1]) # Everything before the last line is reasoning\n",
    "\n",
    "    print(f\"Planner's Reasoning:\\n{reasoning}\")\n",
    "    print(f\"Planner's Decision: {decision}\")\n",
    "\n",
    "    if \"calculate\" in decision:\n",
    "        return {\"planner_reasoning\": reasoning, \"route\": \"calculate\"}\n",
    "    elif \"travel\" in decision:\n",
    "        return {\"planner_reasoning\": reasoning, \"route\": \"travel\"}\n",
    "    else:\n",
    "        return {\"planner_reasoning\": reasoning, \"route\": \"research\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f50cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_agent(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    This agent uses a web search tool, reasons about the findings, and then explains the topic.\n",
    "    \"\"\"\n",
    "    print(\"---RESEARCHER (with SerpApi Web Search)---\")\n",
    "    topic = state[\"topic\"]\n",
    "    \n",
    "    search_results = search_tool.run(topic)\n",
    "    print(f\"Search Results:\\n{search_results}\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are a helpful research assistant. Your goal is to explain a topic based on search results.\n",
    "        \n",
    "        Topic: {topic}\n",
    "        Search Results:\n",
    "        {search_results}\n",
    "\n",
    "        First, provide a step-by-step reasoning of how you will use the search results to construct an explanation.\n",
    "        Then, use '---' as a separator on a new line.\n",
    "        Finally, after the separator, provide the final, brief, easy-to-understand explanation of the topic.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"topic\": topic, \"search_results\": search_results})\n",
    "    \n",
    "    response_text = result.content.strip()\n",
    "    \n",
    "    parts = response_text.split('---')\n",
    "    if len(parts) == 2:\n",
    "        reasoning, explanation = parts[0].strip(), parts[1].strip()\n",
    "    else:\n",
    "        reasoning = \"No specific reasoning provided.\"\n",
    "        explanation = response_text\n",
    "    \n",
    "    print(f\"Researcher's Reasoning:\\n{reasoning}\")\n",
    "    print(f\"Researcher's Explanation:\\n{explanation}\")\n",
    "    \n",
    "    return {\"researcher_reasoning\": reasoning, \"explanation\": explanation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4123bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator_agent(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    This agent uses an LLM Math tool to solve a math problem.\n",
    "    \"\"\"\n",
    "    print(\"---CALCULATOR---\")\n",
    "    topic = state[\"topic\"]\n",
    "    \n",
    "    result = math_tool.invoke({\"question\": topic})\n",
    "    answer = result.get('answer', 'Could not calculate answer.')\n",
    "    \n",
    "    print(f\"Calculator's Result: {answer}\")\n",
    "    return {\"calculator_result\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_planner_agent(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    This agent searches for travel-related information, reasons about it, and provides a summary.\n",
    "    \"\"\"\n",
    "    print(\"---TRAVEL PLANNER---\")\n",
    "    topic = state[\"topic\"]\n",
    "    \n",
    "    # For this example, we'll just use the general search tool.\n",
    "    # A real-world application would use a dedicated travel API.\n",
    "    search_results = search_tool.run(f\"Find information about: {topic}\")\n",
    "    \n",
    "    print(f\"Travel Search Results:\\n{search_results}\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are a helpful travel assistant. Your goal is to summarize travel information for a user.\n",
    "\n",
    "        Query: '{topic}'\n",
    "        Search Results:\n",
    "        {search_results}\n",
    "\n",
    "        First, provide a step-by-step reasoning of how you will use the search results to answer the user's query.\n",
    "        Then, use '---' as a separator on a new line.\n",
    "        Finally, after the separator, provide the final summary for the user.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"topic\": topic, \"search_results\": search_results})\n",
    "\n",
    "    response_text = result.content.strip()\n",
    "\n",
    "    parts = response_text.split('---')\n",
    "    if len(parts) == 2:\n",
    "        reasoning, travel_summary = parts[0].strip(), parts[1].strip()\n",
    "    else:\n",
    "        reasoning = \"No specific reasoning provided.\"\n",
    "        travel_summary = response_text\n",
    "\n",
    "    print(f\"Travel Planner's Reasoning:\\n{reasoning}\")\n",
    "    print(f\"Travel Planner's Response:\\n{travel_summary}\")\n",
    "    \n",
    "    return {\"travel_reasoning\": reasoning, \"travel_result\": travel_summary}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ee4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer_agent(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    This agent takes an explanation and summarizes it in one sentence.\n",
    "    \"\"\"\n",
    "    print(\"---SUMMARIZER---\")\n",
    "    explanation = state[\"explanation\"]\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"You are a summarization expert. Condense the following text into a single, concise sentence:\\n\\n{explanation}\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"explanation\": explanation})\n",
    "    \n",
    "    print(f\"Summarizer's Output:\\n{result.content}\")\n",
    "    return {\"summary\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b382a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_route(state: AgentState) -> Literal[\"research\", \"calculate\", \"travel\"]:\n",
    "    \"\"\"This function is the decision point for our conditional edge.\"\"\"\n",
    "    return state[\"route\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5179a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Graph Definition ---\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add all the agent functions as nodes\n",
    "workflow.add_node(\"planner\", planner_agent)\n",
    "workflow.add_node(\"researcher\", researcher_agent)\n",
    "workflow.add_node(\"calculator\", calculator_agent)\n",
    "workflow.add_node(\"travel_planner\", travel_planner_agent)\n",
    "workflow.add_node(\"summarizer\", summarizer_agent)\n",
    "\n",
    "# Set the entry point to the planner\n",
    "workflow.set_entry_point(\"planner\")\n",
    "\n",
    "# Add the conditional edge for the planner\n",
    "workflow.add_conditional_edges(\n",
    "    \"planner\",\n",
    "    should_route,\n",
    "    {\n",
    "        \"research\": \"researcher\",\n",
    "        \"calculate\": \"calculator\",\n",
    "        \"travel\": \"travel_planner\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Define the standard edges\n",
    "workflow.add_edge(\"researcher\", \"summarizer\")\n",
    "workflow.add_edge(\"summarizer\", END)\n",
    "workflow.add_edge(\"calculator\", END)\n",
    "workflow.add_edge(\"travel_planner\", END) # Travel result is final\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    topic = input(\"Please enter a topic, math problem, or travel query: \")\n",
    "\n",
    "    inputs = {\"topic\": topic}\n",
    "    final_state = app.invoke(inputs)\n",
    "    \n",
    "    print(\"\\n--- FINAL RESULT ---\")\n",
    "    # The final result depends on which path was taken\n",
    "    if final_state.get('summary'):\n",
    "        print(final_state['summary'])\n",
    "    elif final_state.get('calculator_result'):\n",
    "        print(final_state['calculator_result'])\n",
    "    elif final_state.get('travel_result'):\n",
    "        print(final_state['travel_result'])\n",
    "    else:\n",
    "        print(\"An unexpected error occurred.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
