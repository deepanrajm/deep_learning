{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbW9mpFbrRlb"
      },
      "source": [
        "!git clone https://github.com/deepanrajm/deep_learning.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "zQgCfSCFnkyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0MWFfw0rkyr"
      },
      "source": [
        "# Load the training data\n",
        "source_data = Path(\"deep_learning/Generate_Text/sherlock_holmes.txt\").read_text()\n",
        "text = source_data.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cai3crD2rv2M"
      },
      "source": [
        "# Create a list of unique characters in the data\n",
        "chars = sorted(list(set(text)))\n",
        "chars_to_numbers = dict((c, i) for i, c in enumerate(chars))\n",
        "numbers_to_chars = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# Split the text into 40-character sequences\n",
        "sequence_length = 40\n",
        "\n",
        "# Capture both each 40-character sequence and the 41-st character that we want to predict\n",
        "training_sequences = []\n",
        "training_sequences_next_character = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzsqevDarxkk"
      },
      "source": [
        "# Loop over training text, skipping 40 characters forward on each loop\n",
        "for i in range(0, len(text) - sequence_length, 40):\n",
        "    # Grab the 40-character sequence as the X value\n",
        "    training_sequences.append(text[i: i + sequence_length])\n",
        "    # Grab the 41st character as the Y value to predict\n",
        "    training_sequences_next_character.append(text[i + sequence_length])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNG-Ly6Dry_M"
      },
      "source": [
        "# Convert letters to numbers to make training more efficient\n",
        "X = np.zeros((len(training_sequences), sequence_length, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(training_sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(training_sequences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, chars_to_numbers[char]] = 1\n",
        "    y[i, chars_to_numbers[training_sequences_next_character[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKQWfwucr1mz"
      },
      "source": [
        "def generate_new_text(epoch, _):\n",
        "    seed_text = \"when you have eliminated the impossible,\"\n",
        "    new_text = \"\"\n",
        "\n",
        "    # Generate 1000 characters of new text\n",
        "    for i in range(1000):\n",
        "\n",
        "        # Encode the seed text as an array of numbers the same way our training data is encoded\n",
        "        x_pred = np.zeros((1, sequence_length, len(chars)))\n",
        "        for t, char in enumerate(seed_text):\n",
        "            x_pred[0, t, chars_to_numbers[char]] = 1.\n",
        "\n",
        "        # Predict which letter is most likely to come next\n",
        "        predicted_letter_prob = model.predict(x_pred, verbose=0)[0]\n",
        "\n",
        "        # Uncomment these lines to control the amount of randomness.\n",
        "        # # Lower values make the model less random\n",
        "        # randomness = 0.6\n",
        "\n",
        "        # Hack to prevent sum of predictions from adding up to over 1.0 due to floating point precision issues\n",
        "        predicted_letter_prob *= 0.99\n",
        "\n",
        "        # Using the letter probabilities as weights, choose the next letter randomly\n",
        "        next_index = np.argmax(np.random.multinomial(1, predicted_letter_prob, 1))\n",
        "\n",
        "        # Look up the letter itself from it's index number\n",
        "        next_char = numbers_to_chars[next_index]\n",
        "\n",
        "        # Add the new letter to our new text.\n",
        "        new_text += next_char\n",
        "\n",
        "        # Update the seed text by dropping the first letter and adding the new letter.\n",
        "        # This is so we can predict the next letter in the sequence.\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "\n",
        "    # Print the new text we generated\n",
        "    print(new_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(sequence_length, len(chars)))\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(len(chars), activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "SQopoXoppKVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(X, y, batch_size=128, epochs=2,callbacks=[tf.keras.callbacks.LambdaCallback(on_epoch_end=generate_new_text)])"
      ],
      "metadata": {
        "id": "4aBMHrsBpl-8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}