{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWp-u-Y8N-nY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUAsQAah-ThK"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHbJyycmGGba"
      },
      "source": [
        "INIT_LR = 1e-3  # =0.0001\n",
        "EPOCHS = 20\n",
        "BS = 32"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(\"/content/drive/MyDrive/Sport_Scene\"))\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\timage = cv2.resize(image, (224, 224))\n",
        "\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)\n",
        "\n",
        "data = np.array(data) / 255.0\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "Lx48hNrvICqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aeEFrUb-VBZ"
      },
      "source": [
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(labels)\n",
        "labels = encoder.transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "# y_test = np_utils.to_categorical(y_test)\n",
        "# lb = LabelBinarizer()\n",
        "# labels = lb.fit_transform(labels)\n",
        "# labels = to_categorical(labels)\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42)\n",
        "\n",
        "trainAug = ImageDataGenerator(rotation_range=10,\n",
        "                                  width_shift_range=0.1,\n",
        "                                  height_shift_range=0.1,\n",
        "                                  shear_range=0.1,\n",
        "                                  brightness_range=(0.3, 1.0),\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip=True,\n",
        "                                  fill_mode='nearest')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KByhBSjf-lHh"
      },
      "source": [
        "\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(2, 2))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(64, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(4, activation=\"softmax\")(headModel)\n",
        "\n",
        "\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainAug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZu_2K1S-sPD"
      },
      "source": [
        "print(H.history.keys())\n",
        "\n",
        "# Loss Curves\n",
        "plt.figure(figsize=(25, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(H.history['loss'],'-g',linewidth=1.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=14)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=22)\n",
        "\n",
        "# Accuracy Curves\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(H.history['accuracy'],'-g',linewidth=1.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=14)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=22)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}