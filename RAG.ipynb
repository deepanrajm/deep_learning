{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in the PDF: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Analysis of the Example:\\n• Modifier - Blog Post: Here, we are instructing the Language Model to create a\\nmore detailed and in-depth text, as opposed to short, concise tweets.\\n• Topic - Healthy Eating: This is the main focus of our request.\\n• Target Audience - Working Professionals: The model needs to present the\\ninformation in a way that is practical and actionable for working professionals\\nwho may have limited time.\\n• Use of Keywords - SEO Relevance: The model should incorporate keywords\\nand phrases that can enhance visibility on search engines.\\n• Style - Simple, Understandable Style: The model should make the text clear\\nand comprehensible to facilitate easy reading.\\n• Length and Structure - 800 Words, Well-Structured: These requirements help\\ndetermine the length and formatting of the text.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PDFPlumberLoader(r\"D:\\Petramount\\Courses\\AI\\LLM\\1+The+structured+Prompt.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Check the number of pages\n",
    "print(\"Number of pages in the PDF:\",len(docs))\n",
    "\n",
    "# Load the random page content\n",
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepa\\.conda\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created:  4\n",
      "Structured Prompt! A structured prompt consists of a (Modifier) + (Topic) + (Multiple Modifiers). These elements together form the optimized prompt. Modifier: Specifies the type of desired response. Examples: \"Twitter thread,\"\n",
      "\"blog post,\" \"research paper,\" etc. Topic: The main subject or question to be addressed in the response. Additional Modifiers: Additional specific requirements or details to be\n",
      "considered in the response. Examples: Target audience, keywords used, style,\n",
      "length, structure, etc.\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of chunks created: \", len(documents))\n",
    "\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the embedding model\n",
    "embedder = HuggingFaceEmbeddings()\n",
    "\n",
    "# Create the vector store \n",
    "vector = FAISS.from_documents(documents, embedder)\n",
    "retriever = vector.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = \"\"\"\n",
    "1. Use the following pieces of context to answer the question at the end.\n",
    "2. If you don't know the answer, just say that \"I don't know\" but don't make up an answer on your own.\\n\n",
    "3. Keep the answer crisp and limited to 3,4 sentences.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt) \n",
    "\n",
    "llm_chain = LLMChain(\n",
    "                  llm=llm, \n",
    "                  prompt=QA_CHAIN_PROMPT, \n",
    "                  callbacks=None, \n",
    "                  verbose=True)\n",
    "\n",
    "document_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\", \"source\"],\n",
    "    template=\"Context:\\ncontent:{page_content}\\nsource:{source}\",\n",
    ")\n",
    "\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "                  llm_chain=llm_chain,\n",
    "                  document_variable_name=\"context\",\n",
    "                  document_prompt=document_prompt,\n",
    "                  callbacks=None,\n",
    "              )\n",
    "\n",
    "qa = RetrievalQA(\n",
    "                  combine_documents_chain=combine_documents_chain,\n",
    "                  verbose=True,\n",
    "                  retriever=retriever,\n",
    "                  return_source_documents=True,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "1. Use the following pieces of context to answer the question at the end.\n",
      "2. If you don't know the answer, just say that \"I don't know\" but don't make up an answer on your own.\n",
      "\n",
      "3. Keep the answer crisp and limited to 3,4 sentences.\n",
      "\n",
      "Context: Context:\n",
      "content:Structured Prompt! A structured prompt consists of a (Modifier) + (Topic) + (Multiple Modifiers). These elements together form the optimized prompt. Modifier: Specifies the type of desired response. Examples: \"Twitter thread,\"\n",
      "\"blog post,\" \"research paper,\" etc. Topic: The main subject or question to be addressed in the response. Additional Modifiers: Additional specific requirements or details to be\n",
      "considered in the response. Examples: Target audience, keywords used, style,\n",
      "length, structure, etc.\n",
      "source:D:\\Petramount\\Courses\\AI\\LLM\\1+The+structured+Prompt.pdf\n",
      "\n",
      "Context:\n",
      "content:Analysis of the Example:\n",
      "• Modifier - Blog Post: Here, we are instructing the Language Model to create a\n",
      "more detailed and in-depth text, as opposed to short, concise tweets. • Topic - Healthy Eating: This is the main focus of our request.\n",
      "source:D:\\Petramount\\Courses\\AI\\LLM\\1+The+structured+Prompt.pdf\n",
      "\n",
      "Context:\n",
      "content:• Target Audience - Working Professionals: The model needs to present the\n",
      "information in a way that is practical and actionable for working professionals\n",
      "who may have limited time. • Use of Keywords - SEO Relevance: The model should incorporate keywords\n",
      "and phrases that can enhance visibility on search engines. • Style - Simple, Understandable Style: The model should make the text clear\n",
      "and comprehensible to facilitate easy reading. • Length and Structure - 800 Words, Well-Structured: These requirements help\n",
      "determine the length and formatting of the text. \n",
      "source:D:\\Petramount\\Courses\\AI\\LLM\\1+The+structured+Prompt.pdf\n",
      "\n",
      "Question: prompting example\n",
      "\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know because I couldn't find a structured prompt provided in the given context to test against. However, it appears that a specific structure and requirements were mentioned in the original text, which would typically be used for a more detailed task like writing an essay or research paper.\n"
     ]
    }
   ],
   "source": [
    "print(qa(\"prompting example\")[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
