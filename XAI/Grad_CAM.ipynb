{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iy5Cti3Or3kI"
      },
      "outputs": [],
      "source": [
        "# ===================================================================\n",
        "# 1. SETUP: Standard libraries\n",
        "# ===================================================================\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "# ===================================================================\n",
        "# 2. LOAD PRE-TRAINED MODEL AND YOUR UPLOADED IMAGE\n",
        "# ===================================================================\n",
        "# Use a pre-trained ResNet-50 model\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model.eval()\n",
        "\n",
        "# Hooks for Grad-CAM (this part remains the same)\n",
        "final_conv_layer = model.layer4[2].conv3\n",
        "gradients = None\n",
        "activations = None\n",
        "def backward_hook(module, grad_input, grad_output):\n",
        "  global gradients\n",
        "  gradients = grad_output[0]\n",
        "def forward_hook(module, input, output):\n",
        "  global activations\n",
        "  activations = output\n",
        "final_conv_layer.register_forward_hook(forward_hook)\n",
        "final_conv_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "# Image preprocessing steps (this part remains the same)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Define the filename of the image you uploaded\n",
        "image_filename = \"/content/cat and dog.jpg\"\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    # Open your local image file\n",
        "    img = Image.open(image_filename).convert('RGB')\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{image_filename}' was not found.\")\n",
        "    print(\"Please make sure you have uploaded the file and the filename is correct.\")\n",
        "    # Create a dummy image to prevent the rest of the code from crashing\n",
        "    img = Image.new('RGB', (224, 224), color = 'red')\n",
        "\n",
        "# Preprocess the image and add a \"batch\" dimension\n",
        "input_tensor = preprocess(img).unsqueeze(0)\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# 3. PERFORM CLASSIFICATION & GRAD-CAM (this part remains the same)\n",
        "# ===================================================================\n",
        "output = model(input_tensor)\n",
        "pred_class_idx = output.argmax().item()\n",
        "\n",
        "# Load ImageNet class labels\n",
        "!wget -q https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
        "with open('imagenet_classes.txt') as f:\n",
        "    labels = [line.strip() for line in f.readlines()]\n",
        "print(f\"Prediction: {labels[pred_class_idx]}\")\n",
        "\n",
        "output[:, pred_class_idx].backward()\n",
        "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "for i in range(activations.shape[1]):\n",
        "    activations[:, i, :, :] *= pooled_gradients[i]\n",
        "heatmap = torch.mean(activations, dim=1).squeeze().detach().numpy()\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "\n",
        "# ===================================================================\n",
        "# 4. VISUALIZE THE RESULTS (this part remains the same)\n",
        "# ===================================================================\n",
        "resized_heatmap = cv2.resize(heatmap, (img.width, img.height))\n",
        "colored_heatmap = plt.cm.jet(resized_heatmap)[:, :, :3]\n",
        "original_img_array = np.float32(img) / 255\n",
        "superimposed_img = (colored_heatmap * 0.4) + original_img_array\n",
        "superimposed_img = np.clip(superimposed_img, 0, 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(superimposed_img)\n",
        "plt.title(f\"Grad-CAM: Why '{labels[pred_class_idx]}'?\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ]
}